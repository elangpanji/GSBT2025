{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BayesianSearchCV\n",
        "\n",
        "1. Apa itu hyperparameter tuning?\n",
        "2. Jelaskan metode BayesSearchCV!\n",
        "3. Bagaimana cara kerja BayesSearchCV?\n",
        "4. Apa kelebihan BayesSearchCV dibandingkan metode hyperparameter tuning lainnya?\n",
        "\n"
      ],
      "metadata": {
        "id": "pjbXCL2nNB9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hyperparameter adalah parameter yang ditentukan sebelum training model. Contohnya depth pada decision tree, learning rate pada gradient boosting, C/gamma pada SVM). Sehingga hyperparameter tuning ialah proses mencari kombinasi hyperparameter terbaik supaya model menghasilkan performa maksimal (misal akurasi tinggi, error rendah).\n",
        "2. BayesSearchCV adalah metode hyperparameter tuning berbasis Bayesian Optimization. BayesSearcCV tersedia di library scikit-optimize (skopt). Metode ini menggunakan model probabilistik untuk memprediksi area hyperparameter mana yang kemungkinan menghasilkan hasil bagus lalu menguji area tersebut.\n",
        "3. Cara kerja BayesSearcCV ialah memulai dengan beberapa kombinasi acak lalu dicoba dan dievaluasi. Bangun model probabilistik (misalnya Gaussian Process) yang memperkirakan hubungan antara hyperparameter dan skor (accuracy/error. Gunakan model tersebut untuk memprediksi area \"menjanjikan\" di ruang hyperparameter. Pilih kombinasi terbaik berikutnya untuk diuji dan bukan random. Ulangi langkah sebelumnya sampai jumlah iterasi tercapai. Ambil kombinasi dengan performa terbaik.\n",
        "4. Kelebihan BayesSearchCV dibandingkan metode hyperparameter tuning lainnya:\n",
        "*   GridSearchCV boros waktu, coba semua kombinasi walaupun tidak perlu. Namun, BayesSearchCV lebih hemat dan fokus ke area menjanjikan\n",
        "*   RandomizedSearchCV lebih cepat dari grid tapi masih random dan bisa melompati kombinasi bagus. Tetapi, BayesSearchCV menggunakan informasi dari percobaan sebelumnya (adaptif)\n",
        "*   Manual Tuning lebih subjektif, rawan bias, dan memakan waktu. BayesSearchCV sistematis dan terotomatisasi"
      ],
      "metadata": {
        "id": "t6D6YDaQsTm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2o0dt8txGE1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f4e398-06a2-406a-d4f3-d1a762bf42fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ],
      "source": [
        "# import library\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#improt library lagi\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TOGVwjKJu0K3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)"
      ],
      "metadata": {
        "id": "v7ENirBIHIYz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan Model dan parameter yang akan dioptimasi (Ruang Hyperparameter)\n",
        "# import library\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Definisikan model\n",
        "svc = SVC()\n",
        "\n",
        "# Definisikan ruang hyperparameter\n",
        "param_space = {\n",
        "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "    'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "    'kernel': Categorical(['linear', 'rbf', 'poly'])\n",
        "}\n",
        "\n",
        "# BayesSearchCV setup\n",
        "opt = BayesSearchCV(\n",
        "    estimator=svc,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=32,\n",
        "    cv=3,\n",
        "    random_state=0,\n",
        "    n_jobs=-1\n",
        ")\n"
      ],
      "metadata": {
        "id": "vmyqOLU1IO3T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi Optimisasi Menggunakan BayesianSearchCV"
      ],
      "metadata": {
        "id": "Ip5U8cL4OLUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi BayesSearchCV\n",
        "opt = BayesSearchCV(\n",
        "    estimator=svc,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=32,\n",
        "    cv=3,\n",
        "    random_state=0,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "BC0k0vXKOBJk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan optimisasi\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "# Tampilkan hasil terbaik\n",
        "print(\"Best Parameters:\", opt.best_params_)\n",
        "print(\"Best CV Score:\", opt.best_score_)\n"
      ],
      "metadata": {
        "id": "EYoUwsYCOB5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f7e68a-5072-4cc6-d333-6eea9adcdc19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: OrderedDict({'C': 0.0012602593949011189, 'gamma': 7.117469405170288, 'kernel': 'poly'})\n",
            "Best CV Score: 0.9642010431484116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi Model di data uji\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "# Hitung akurasi\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "sox5OZx6OD0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bb8878-e979-43fc-a4c5-35857240709f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9736842105263158\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      0.94      0.97        16\n",
            "           2       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        38\n",
            "   macro avg       0.97      0.98      0.97        38\n",
            "weighted avg       0.98      0.97      0.97        38\n",
            "\n"
          ]
        }
      ]
    }
  ]
}